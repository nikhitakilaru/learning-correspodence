Learning Correspondences Across Domains for Exemplar-Based Image Translation
This project explores exemplar-based learning across different domains using deep learning techniques. It focuses on how to leverage a small set of representative examples (exemplars) from a source domain to improve model performance when applied to a target domain with limited or no labeled data.

The key idea is to select and utilize informative exemplars that best capture the variations within the source domain and help bridge the domain gap during adaptation. This approach can be useful in scenarios like transfer learning, few-shot learning, and domain adaptation, where labeled data is scarce in the target domain.

The implementation is organized within a Jupyter Notebook and involves:
- Feature extraction from source domain data.
- Exemplar selection strategies.
- Training models with a combination of source data and selected exemplars.
- Evaluation across different domain shifts to measure generalization performance.

The methods applied aim to minimize the domain discrepancy and enhance the adaptability of machine learning models to new, unseen domains.
